---
title: " ECO 602 - Analysis of Environmental Data"
subtitle: "Final Project Template"
author: "Avery Panza"
date: "Fall 2020"
output:
  html_document:
    theme: readable
    toc: TRUE
    toc_float: TRUE
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
options(knitr.duplicate.label = TRUE)
```




<!-- The following text won't be displayed in your document.  It tells R how to make nicer looking buttons for your tabbed content. -->

<style type="text/css" rel="stylesheet">

.btn {
    border-width: 0 0 0 0;
    font-weight: normal;
    text-transform: none;
}

.btn-default {
    color: #2ecc71;
    background-color: #ffffff;
    border-color: #ffffff;
}
</style>



# Introduction 

This is my Final Project for ECO 602 2020, Part 1 is a compendium of r functions while part 2 is specific to the delomys data. Enjoy.


# Functions 1: Data Structure Functions {.tabset .tabset-pills}

## `c()`

The following is the markdown text needed to reproduce my code example for `c()`:


The function `c()` *combines* or *concatenates* its arguments into a vector (a 1-dimensional data structure consisting of 1 or more elements).

- All of the elements must be of the same *type*.
  - I can't combine character and numeric types in the same call to `c()`

Here's two examples using numeric and character data types:

```{r}
# Create a vector of numbers:
num_vec  = c(1, 4, 8, 9, 13)

# Create a vector of characters:
char_vec = c("a", "fish", "data is cool")
```

I can show the contents of a vector by typing the name of the vector, or using the `print()` function.

```{r}
# Typing the name of the vector into the console prints the contents
num_vec

# The print() function accomplishes the same task:
print(char_vec)
```


## `data.frame()`

The 'data.frame()' function creates a table where each column contains values from the given variable which can be thought of like fields. Each row contains values from each of the column fields that applies to that row.

- The column names should be unique from one annother and also cannot be left blank. 
- The data input into your data frame can contain the following data types, however all values in a column should have matching data types.
  - Numerical Values
  - factor values
  - Character (text) type
- To add a date you have to use the 'as.Date' function.
  - When adding dates to your data frame, you must structure it as (Year-Month-Day).
  - test

```{r}
#Creates a data frame.
firetruck.data <- data.frame(
  truck_id = c (1:5),
  truck_name = c("The Inferno","The Extinguisher","The Blaze","Hot Stuff","The Dalmatian"),
  fires_extinguished = c(25,100,52,211,2),
#if you want to add dates to your data frame, here's how you'd do that.  
  entered_service = as.Date(c("2020-01-12","2017-03-21","2016-06-28","2012-09-01","2020-10-01")),
  stringsAsFactors = FALSE
)
```
I can print the firetruck.data by using the print() function:
```{r}
#print the example data.frame() function.
print(firetruck.data)

```
## `matrix()`
The 'matrix()' function allows you to take a set of basic type data and arrange it into a rectangular table. The following examples will show you how to both create a matrix as well as manipulate the data set to show specific columns, rows, and even rename them. 

- Here's a simple way to create a matrix.

```{r}
Matrix_1 = matrix(
  c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), #Our sample data values.
  nrow = 3, #Number of rows in this matrix.
  ncol = 4, #Number of columns in this matrix.
  byrow = TRUE)
print(Matrix_1)
```
Now lets get into how you can extract specific information from this matrix. This could be useful if the matrix was much larger.

- Say that you want to extract a specific data value from row x and column y. You would use the expression Matrix_1[x, y].
```{r}
Matrix_1[2, 4]  #We're telling r to show us the data value in the 2nd row and the 4th column.
```

- Now lets say you want to extract an entire row from the matrix. You would use the expression Matrix_1[x, ]. 
  - This will work exactly the same way for columns with the expression Matrix_1[ ,y] but I will only show the row example here.
   
```{r}
Matrix_1[1, ]  #Here we are telling r to show us all values in the 1st row.
```

- r also allows you to call up multiple columns or rows at a time shown in the following function.

```{r}
Matrix_1[ ,c(1,4)]  #We're telling r to show us the 1st and 4th columns. 
```

- Lastly, if you want to rename your columns or rows you can. This way you can extract values from the matrix my name.

```{r}
dimnames(Matrix_1) = list(
  c("row_1", "row_2", "row_3"),  #Row names
  c("col_1", "col_2", "col_3", "col_4")  #Column names
)
Matrix_1
```
## `length()`
The 'length()' function is used when you need to determine how many values you have in a data set. The example I'll go through here is simple yes, but gets the point across.

- In this example, we'll be using the same matrix we used in the matrix tab. Lets pretend though that we dont know how many values are in our matrix so that we can illustrate a use case for the 'length()' function. 

```{r}
(Matrix_1 <- matrix(1:12, 3, 4))  #Hey look, here's a different way to structure r code for a matrix!
length(Matrix_1)
```

- You can see how the 'length()' function simply counts the number of values in the matrix. 
  - This works not only for a matrix but can be applied to specific columns as well to determine a count statistic.

## `nrow()`
The 'nrow()' function is very useful if you simply need to determine how many rows in your table, data set or matrix.

- For this example I'll be using the same matrix as I used earlier in order to demonstrae a use case for the 'nrow()' function.

```{r}
(Matrix_1 <- matrix(1:12, 3, 4)) #Again, just pretend that we don't know how many rows are in this matrix.
nrow(Matrix_1) #calculates number of rows in matrix.
```

- Here we can see that the 'nrow(Matrix_1)' function returned a value of 3 which is indeed the number of rows in our matrix. 

## `ncol()`

Similar to the *nrow()'* function, the *ncol()* function calls for the number of columns in a data frame or a matrix. 

- Again, the following example will call for the number of columns in the two matrices and the single data frame created in previous examples of this function section.
Copied!

```{r ncol_example_1}
ncol(firetruck.data)
ncol(Matrix_1) 
```


## `dim()`

The *dim()* function is used to set or retrieve the dimension of a matrix or data frame. When using this function to retrieve the dimension, output numbers indicate the number of rows followed by columns. This function can't retrieve the dimension of a single vector. 

- Examples of how to retrieve the dimensions of a matrix or a data frame, using previously created matrix and data frame, are below:

```{r dim_example_1}
dim(Matrix_1)  # Retrieves dimensions of matrix.
dim(firetruck.data) # Retrieves dimension of data frame.
```

- A different way to use the dim function is to set the size of a matrix or data frame. The following example creates a vector of a given dimension, and uses the dim function to set the data values into a table. 

```{r dim_example_2}
Dim_1 <- c(1:100) # Create a vector of numbers.
Dim_1 # Print the created vector.

dim(Dim_1) <- c(10, 10) # Use dim function to break the vector into a data frame, or a matrix of 10 rows by 10 columns
Dim_1 # Print the restructured vector, which is now a data frame.

str(Dim_1) # Structure of the data frame, which are two un-named vectors of integer values 1 through 10. 
```


# Functions 2: Numerical Data Exploration  {.tabset .tabset-pills}

## `summary()`

The *summary()* function is used to produce result summaries of various model fitting functions. It provides statistics on a data set, such as min, the first quantile, the median, the mean, the 3rd quantile, and the max value of our data.

- The following shows how the summary function can be applied to a vector:
```{r summary_example_1}
vector_1 <- c(1:500) # Creates a vector of numbers.
summary(vector_1) # Print the summary of the vector.
```

- The next example shows how the summary function is used as well as how it can be applied to a data frame.
```{r summary_example_2}
dat_2 <- data.frame( # Creates test data frame.
  A = 1:10, # Names 1st column "A" to be a vector of integers: 1 to 10.
  B = letters[1:10], # Names the 2nd column "B" to be a vector of letters, the first 10 letters of the alphabet.
  C = 4, # Names the 3rd column "C", C = 4.
  D = c(TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE)) # Names the 4th column "D" to be a logical vector of 10 true or false values.

dat_2 # Prints test data frame.

summary(dat_2) # Prints summary of the data frame.
```

- The 'summary()' function can also be used to examine linear regression models, as shown in the example below. We will be using the *palmerpenguins* data set. 
```{r summary_example_3}
require(palmerpenguins) # Loads in the Penguin data.
penguin_dat = droplevels(subset(penguins, species != "Gentoo")) # Creates a data frame specific to Gentoo Penguins.
summary(penguin_dat) # Prints summary data frame.
summary(lm(body_mass_g ~ bill_length_mm, data=penguin_dat))# Prints summary of linear regression model of data set's variables (body mass and bill length)

```


## `mean()`

The *mean()* function calculates the arithmetic mean of a numeric input vector.

- A basic application can be applied to vectors, shown here:
```{r mean_example_1}
vector_2 <- c(1:100) # Creates a vector of numbers.
mean(vector_2) # Apply mean function
```

- The next example shows how to derive a mean value in a vector that has some null values, since letters cannot be computed arithmetically. 
```{r mean_example_2}
vector_3 <- c(1, 5, 8, 3, NA, 0, 9, 78, 10, -2, -16) # Creates a vector of numbers with an NA value.
mean(vector_3) # Applies mean function - result is an error.
mean(vector_3, na.rm = TRUE) # Tells r to remove the NA values before computing the mean. The results show the correct numerical value.
```

- The following examples applies the mean function to a real data set. We will use the *palmerpenguins* data set again.
```{r mean_example_3}

head(penguin_dat) # Prints head rows of the data set.
mean(penguins$bill_length_mm) # Calculates the mean of the bill length column. Results show 'NA' due to some NA values. 
mean(penguins$bill_length_mm, na.rm = TRUE) # Tells r to remove NA values before calculating mean. Results show the desired numerical values. 
```



## `sd()`
 
The *sd()* function calculates the standard deviation (sd) of a numeric input vector. This is the square root of data variance.

- One example of calculating the standard deviation for a vector is shown below. We will use a vector that we made earlier:

```{r sd_example_1}
vector_2     #Prints vector.
sd(vector_2) # Applies the standard deviation calculation to the vector.
```

- The next example shows how to calculate the standard deviation for a vector with NA or NULL values. Again, we will use one of the vectors we created earlier with an NA value:

```{r sd_example_2}
vector_3               #Prints the vector.
sd(vector_3) # Applies the standard deviation (sd) calculation to the vector. Results show 'NA' due it containing NA values. 
sd(vector_3, na.rm = TRUE) # Exactly like the previous functions, "na.rm" can be used to tell r to remove the NA value before calculating the mean. Results show the desired numerical values.
```

- Our Next example shows how to calculate the standard deviation for a data set. We will use the *palmerpenguins* data set again to visualize this.

```{r sd_example_3}

head(penguin_dat)              # Prints the head rows of the data set.
sd(penguin_dat$bill_length_mm) # Applies the standard deviation to a specified variable using the "$". Again, there is an NA value in this variable. 
sd(penguin_dat$bill_length_mm, na.rm = TRUE) # Tell r not to calculate NA values. Results show numerical values. 
```


# Functions 3: Graphical Data Exploration {.tabset .tabset-pills}

One of the biggest use cases for using R is due to its graphic capabilities. 
In R, there are many ways of creating graphical representations of your data. Some common examples are histograms, boxplots, and scatterplots. 

## 'par()' 

The *'par()' function takes multiple graphs and combines them into a single graphical representation.

- The function 'mfrow=c(nrows, ncols)' creates a matrix of 'nrows' (number of rows) by 'ncols' (number of columns) plots that are populated by row. Using the 'mfcol=c(nrows, ncols)' function populates the matrix by column.

- An example of how to use the *'par()'* function with the *mfrow=c(2,2)'* function is shown here:

```{r par_example_1}

attach(penguins) # Species which data set to use. 
par(mfrow=c(2,2)) # Specifies 2 rows and 2 columns.

plot(
  flipper_length_mm ~ body_mass_g, 
  data = penguins, 
  main = "Penguin Flipper Length vs Body Mass", 
  xlab = "Flipper Length (mm)", 
  ylab = "Body Mass (g)", 
  col = "pink", 
  pch = 16,
  frame = FALSE,
  xlim = c(2500,6500), 
  ylim = c(160,240))

abline(lm(flipper_length_mm~body_mass_g, data=penguins), col="red")

plot(
  bill_length_mm ~ body_mass_g, 
  data = penguins, 
  main = "Penguin Bill Length vs Body Mass", 
  xlab = "Bill Length (mm)", 
  ylab = "Body Mass (g)", 
  col = "pink", 
  pch = 16, 
  frame = FALSE,
  xlim = c(2500,6500), 
  ylim = c(20,70))

abline(lm(bill_length_mm~body_mass_g, data=penguins), col="red")

boxplot(body_mass_g ~ sex * species, 
        data = penguins, 
        main = "Penguin Body Mass Conditional Box Plot",
        xlab = "Species and Sex", 
        ylab = "Body Mass (g)", 
        frame = FALSE, 
        notch = TRUE, 
        col = (c("red", "red", "orange", "orange", "yellow", "yellow")))

boxplot(body_mass_g ~ sex * species, 
        data = penguins, 
        main = "Penguin Bill Length Conditional Box Plot",
        xlab = "Species and Sex", 
        ylab = "Bill Length (mm)",
        frame = FALSE, 
        notch = TRUE, 
        col = (c("red", "red", "orange", "orange", "yellow", "yellow")))
```


## 'plot()'

The *'plot()'* function is used to create scatter plots of your data. 

- Our first example will show how to create a scatterplot using the *palmerpenguins* data.

```{r scatterplot_1, fig.asp=0.7, fig.height=20}
require(palmerpenguins) # Loads in the penguins package
plot(bill_length_mm ~ body_mass_g, # First variable specifies x direction, Second variable specifies y direction of graph.
     data = penguins)# Specifies data set.
```

- The next example will show how to create a more in depth scatterplot, using the same *palmerpenguins* data. In addition, the following example will adjust the x and y limits of the graph. 

```{r scatterplot_2, fig.asp=0.7, fig.height=20}
plot(
  bill_length_mm ~ body_mass_g, # First variable (x direction), Second variable (y direction) of the graph.
  data = penguins, # Specifies the data.
  main = "Penguin Data Example 1 Scatterplot", #Adds a title.
  xlab = "Body Mass", # Names the x coordinate.
  ylab = "Bill Length", # Names the y coordinate,
  col = "yellow", # Defines the color
  pch = 16, #pch numbers represent different graphical symbols
  xlim = c(2500,6500), # Adjusts the x coordinate limit
  ylim = c(20,70)) # # Adjusts the y coordinate limit
```

## 'hist()'

The *'hist()'* function is used to create histograms data. Histograms are great choice when analyzing general distribution of a variable(s).

- The first example below shows how to create a simple histogram, and uses the *palmerpenguins* data again:
  - Histograms show specific variables (assigned by you) in the x axis and frequency (occurrence) in the y.
  - If frequency is set as FALSE, the y axis shows density.

```{r histogram_1, fig.asp=0.7, fig.height=20}
hist(penguins$body_mass_g) # Specifies data set and one variable to graph.
```

- The second example shows how to create a more complex histogram of a data set:

```{r histogram_2}
hist(penguins$body_mass_g, 
     breaks = 50, # Designates the number of breaks (bins) between bars along the x axis. This, in many cases reveals more detailed variation in the numerical values and trend of the graph.
     main = "Penguin Body Mass Histogram", # Title
     xlab = "Body Mass (g)",# Names the x axis.
     ylab = "Count", # Names the y axis.
     col = "purple", # Specifies color.
     xlim = c(2000,7000), # Adjusts the x coordinate limit
     ylim = c(0, 30)) # Adjusts the y coordinate limit
```

- Histograms can also be used to develop density plots, which is a curve that represents the variations in the data.

```{r histogram_3}
plot(density
     (penguins$body_mass_g, # Specifies data, and one variable to graph.
       na.rm = TRUE), #Tells R to remove the NA value before calculating curve.
     main = "Penguin Mass Density Plot", #Names the graph
     col = "red", #Specifies color
     frame = FALSE) #Specifies no box frame
```

## 'boxplot()'

The *'box()'* function is used to create box plot diagrams of the data. Boxplots are a type of graphical mapping that shows data distribution, its central value indicated by the black bar, and also its variability shown as the lowermost and uppermost boundaries of the box. Boxplots can also compare multiple sets of data in a single representation, which is why they are very useful in making comparisons.

- The first box plot example shows a simple, single variable analysis. Again, using the *palmerpenguins* data, this graphs penguin body mass conditioned on species. 

```{r boxplot_example_1}
summary(penguins) # Prints summary of data set.
boxplot(body_mass_g~species, # Specifies two variables.
        data = penguins) # Specify data set.
```

- The second example is of a *conditional* box plot, which shows several variables that you can then compare. Again, using the *palmerpenguins* data set, we will graph penguin body mass conditioned on both species and sex. 

```{r boxplot_example_2}
boxplot(body_mass_g ~ sex * species, # Specifies three variables.
        data = penguins) # Specifies data set.
```

- Here is one last example which can be used with box plots to enhance the representation of data:

```{r boxplot_example_3}
boxplot(body_mass_g ~ sex * species, # Specifies three variables.
        data = penguins, # Specifies data set.
        main = "Penguin Body Mass Conditional Box Plot", # Names the box plot
        xlab = "Species and Sex", # Conditional variables.
        frame = FALSE, # Specifies no box frame of graph, otherwise TRUE as default
        notch = TRUE, # Specifies notch, otherwise FALSE as default; helps visualize the mean.
        col = (c("red", "orange"))) # Specifies colors.

```


# Functions 4: Distribution Functions {.tabset .tabset-pills}

The following section demonstrates some of the most common probability distribution functions which describe the likelihood of obtaining the possible values that a random variable can assume. These equations are split into two categories, normal distribution functions and binomial distribution functions. 

The main difference between normal and binomial distribution functions is that they answer two different questions. Normal distribution functions calculate the probability of a *single trial outcome*, in contrast binomial distribution functions calculate probability for *one or multiple trials* to answer the same questions, where each trial is run independently. 

The two types of questions these functions answer are defined as the *“d”*, *“p”* and *“q”*	prefix in the scripts. 

- For a normal distribution, the functions are defined as: *dnorm*, *pnorm* and *qnorm*. 
- For a binomial distribution, the functions are defined as: *dbinom*, *pbinom* and *qbinom*.

- These three different commands for each distribution type indicate the following functions:
  - *“d”*	returns the height of the probability density function
  - *“p”*	returns the cumulative density function
  - *“q”*	returns the inverse cumulative density function (quantiles)

- Normal distribution functions have two parameters: *µ* (mean) and *σ* (sd or standard deviance)
   - The Standard Normal distribution has µ = 0 and σ = 1
   - The mean moves the curve to the left or right.
   - The standard deviation σ controls the width and flatness.
  
- Binomial distribution functions work similarly to the normal distribution commands. However, they have two additional parameters: *n* (number of trials, referred to as *"size"*) and *p* (probability of the success of a single trial, referred to as *"prob"* in the script). For the number of trials, the value must be an integer in order for these functions work correctly.


## 'dnorm()'

*dnorm(x, mean, sd)*

The *'dnorm()'* function returns the height of the probability distribution for each point in the data set, given the three parameters x (or independent variable), mean, and sd (standard deviation). The *"d"* in dnorm stands for *"density."* Thus, the command dnorm is designed to provide values of the probability density function for the normal distribution.

- Mean = 0 and sd = 1 are the default arguments for the *'dnorm()'* function, shown in the simple example below:

```{r dnorm_example_1}
dnorm(0) #x value is specified as zero, mean = 0 and sd = 1 by default.
dnorm(0, mean = 0, sd = 1) # This function can be written like this. 
dnorm(0, 0, 1) # This function can also be written like this as well.
```

- The next example will perform the *'dnorm()'* function using a normally distributed vector of x variables to show a normal distribution function.  This example assumes the mean = 0, and sd = 1

```{r dnorm_example_2}
x_dnorm <- seq(- 5, 5, by = 0.05) # Create a sequence of equally spaced numbers between specified values.
y_dnorm <- dnorm(x_dnorm) # Apply the dnorm function
plot(x_dnorm, y_dnorm, # Plot dnorm values
     type="l", # Specifies a line type graph, default is open circle points
     lwd=2, # Specifies line thickness
     col ="blue", # Specifies line color
     xlab = "X", # Specifies x-axis title
     ylab = "Y") # Specifies y-axis title
axis(1, at = -5:5) #Specify x-axis values
```

- The next example will perform the same *'dnorm()'* function while altering the mean and sd values to show it's impact on the graphed curve. A lower mean value shifts the curve (shifting the mean value) to the left. The higher sd value widens and flattens the curve. 

```{r dnorm_example_3}
x_dnorm <- seq(- 5, 5, by = 0.05) 
y_dnorm <- dnorm(x_dnorm, mean = -1, sd = 2) # Apply the dnorm function, specify mean and sd values.
plot(x_dnorm, y_dnorm,
     type="l", 
     lwd=2, 
     col ="blue",
     xlab = "X", 
     ylab = "Y") 
axis(1, at = -5:5) 
```

- This function is useful in deriving a likelihood probability for a specific value. An example that was learned in class referenced a fish population. This function was used to answer the question: *"Is catching a fish 6cm length more likely than catching a fish of 14.5cm length"?*
Looking at a normal distribution graph, and locating the x value of both 6 and 14.5, the y-axis value can be derived which indicates that percentage probability. Results of this example indicated that for an x=6, the y (or the f(x)) was 0.04, while for an x=14.5, the y value was .07, which means that catching a length of 14.5 was more probable.

## 'pnorm()'

*pnorm(q, mean, sd, lower.tail)*

The *'pnorm()'* function computes the probability that a normally distributed random number will be less than that number. This function is also referred to as the *“Cumulative Distribution Function.”* It accepts the same options as dnorm, and calculates the probability as the cumulative area under the distribution curve. The total area under the curve is always equal to 1, or 100% probability. The *lower.tail* variable in the command is logical. When *TRUE* (which is the default), it implies the probability of less than or equal to x (or *q*), and when *FALSE*, it implies a probability of greater than or equal to x (or *q*). 

- pnorm() differs from dnorm(), which calculates a definite y value for each exact value of x, the pnorm is used if we want to know the probability of all values of x that are less than a chosen value. 

- Similarly to dnorm, the mean = 0 and sd = 1 which are the default arguments for the *'pnorm()'* function, as depicted in the example below. The result will always be .5 in this example, as there is 50% probability of values being within the first half of the area underneath the normal distribution curve.

```{r pnorm_example_1}
pnorm(0) #x value is zero, mean = 0 and sd = 1 (defaults).
pnorm(0, mean = 0, sd = 1) # One way to write this function. 
pnorm(0, 0, 1) # A different way of writing this function.
```

- The next example will go through the *'pnorm()'* function using a previously developed normal distribution curve. This example assumes the mean = 0, and sd = 1.

```{r pnorm_example_2}
x_dnorm <- seq(- 5, 5, by = 0.05) # Repeated normal distribution curve from previous example.
y_dnorm <- dnorm(x_dnorm) 
plot(x_dnorm, y_dnorm, 
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") 
axis(1, at = -5:5) 

x_pnorm <- seq(-5, 1, by = 0.05) # Creates a sequence of equally spaced numbers between specified values for the pnorm function. In this example we are looking at values of x < 1.
y_pnorm <- dnorm(x_pnorm) #Apply dnorm function
polygon(c(-5,x_pnorm, 1),c(0,y_pnorm,0),col="red") # Plots the dnorm function as an area under the curve. We selected the area of x < 1. 
```

- To verify this illustrated concept:

```{r pnorm_example_3}
pnorm(1, 0, 1) # Verify this graphic example. Result is that the probability of x being less than 1 is 84%. Our graph looks correctly done as a visual representation of this concept.
```

- This function is useful for deriving a likelihood probability between two values, or a range of values. An example that was learned in class referenced a fish population, and this function was used to answer a question such as: *"What is the probability of of catching a fish that weighs 153 grams of less"?*
Looking at a normal distribution graph, locating the x value of 153, and calculating the area underneath the curve from that specified value to the left resulted in a value of 0.6 or 60%. 

- An important nuance is that this function always calculates the entire area to the left of a specified x value. So, if we are looking for a range between two values, we would have to subtract the smaller area to the left of the specified range value from a larger area to the left of the second range value. See an example of this below:

```{r pnorm_example_4}

x_dnorm <- seq(- 5, 5, by = 0.05) # Repeat the normal distribution curve from previous example first
y_dnorm <- dnorm(x_dnorm) 
plot(x_dnorm, y_dnorm, 
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") 
axis(1, at = -5:5) 

x_pnorm <- seq(-1, 1, by = 0.05) 
y_pnorm <- dnorm(x_pnorm) 
polygon(c(-1,x_pnorm, 1),c(0,y_pnorm,0),col="red") # Plot dnorm function as an area under the curve. We selected cumulative range area of -1 < x < 1. 
```

- To verify this illustrated concept:

```{r pnorm_example_5}
pnorm(1, 0, 1) - pnorm (-1, 0, 1) # Verify this graphic example. Result is that the probability of a range of x being between values of -1 and 1 is 68%. Our graph looks correctly done as a visual representation of this concept.
```

## 'qnorm()'

*qnorm(p, mean, sd, lower.tail)*

The *'qnorm()'* function computes the inverse of the pnorm function. The input is the desired percentile of probability and the output is the range of x values that meets that percentile. The *lower.tail* variable in the command is logical. When *TRUE* (which is default), it implies probability of less than or equal to x (or *p*), and when *FALSE*, it implies greater than or equal to x (or *p*). 

- Similar to dnorm, and pnorm functions, Mean = 0 and sd = 1 are the default arguments for the *'qnorm()'* function, as shown in the simple example below.

```{r qnorm_example_1}
qnorm(.9) #probability value is specified as 90%, mean = 0 and sd = 1 by default.
qnorm(.9, mean = 0, sd = 1) # This function can be written like this. 
qnorm(.9, 0, 1) # This function can also be written like this as well.
```

- It must be emphasized that the area under the curve to the left is used when applying both commands *pnorm* and *qnorm*. If we are to solve for an area to the right of an x value, we must perform a similar subtraction process, where we subtract that percentage input from a value of 1, or 100%.

- This function is useful in deriving a range of values values, or a range of values. An example that was learned in class referenced a fish population, and this function was used to answer a question such as: *"What is the 90th percentile of fish lenghts?* or, in other words, *What lenght will 90% of the fish population be lower than?*
Looking at a normal distribution graph, locating the x value at 90% of shaded area underneath the curve derived an x value of 13.28, meaning that 90% of the fish is 13.28 mm long or less. 

## 'dbinom()'

*dbinom(x, size, prob)*

Similar to normal distribution functions, the *'dbinom()'* function shows the density. It helps to find the individual probabilities as well as a range of probabilities. It provides the probability of a number of successful trials (*x*), from a number of total trials (*size*), based on a probability of a positive result for each trial (*prob*). 

- The *'dbinom()'* function example below asks the probability of obtaining 10 or less successful outcomes, with a trial size of 10 and a probability of 20%. The follow up scripts will increase the probability and the number of trials to compare them. 

```{r dbinom_example_1}

dbinom(10, 10, 0.2) # This function asks for 10 successful outcomes.
dbinom(10, size = 10, prob = .2) # This is how you write this function. 
dbinom(10, 10, .2) # Here is another way to write this.

dbinom(10, 10, .6) # Changing the probability for comparison

dbinom(10, 20, .2) # Changing the size, or number of trials, for comparison

dbinom(10, 20, .6) # Changing the size and probability for comparison

dbinom(0:10, 10, .2) #We can also ask for a range of 10 or less successful outcomes using this function. The second example below illustrates these ranges graphically.

```

- In the following example, we will plot these concepts into line graphs, for comparisons:

```{r dbinom_example_2}
x_dbinom <- seq(0, 10, by = 1) # Creates a sequence of equally spaced numbers between specified values.

y_dbinom <- dbinom(x_dbinom, size = 10, prob = .2) # Apply the dbinom function.
plot(x_dbinom, y_dbinom, # Plot dbinom values.
     type="l", # Specifies a line type graph (default is open circle points).
     lwd=2, # Defines the line thickness.
     col ="orange", # Defines line color.
     xlab = "X", # Defines x-axis title.
     ylab = "Y") # Specifies y-axis title.

dbinom(0:10, 10, .2) #The resulting answers correspond with the y-axis probability for each x value in the range of 0 to 10.

y_dbinom <- dbinom(x_dbinom, size = 10, prob = .6) # Changing the probability to compare.
plot(x_dbinom, y_dbinom, 
     type="l", 
     lwd=2, 
     col ="red", 
     xlab = "X", 
     ylab = "Y") 

dbinom(0:10, 10, .6) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

y_dbinom <- dbinom(x_dbinom, size = 20, prob = .2) # Changing the size for comparison.
plot(x_dbinom, y_dbinom, 
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") 

dbinom(0:10, 20, .2) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

y_dbinom <- dbinom(x_dbinom, size = 20, prob = .4) # Changing the size and probability for comparison.
plot(x_dbinom, y_dbinom, 
     type="l", 
     lwd=2, 
     col ="red",
     xlab = "X", 
     ylab = "Y") 

dbinom(0:10, 10, .4) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

```

- A more practical example of where the *'dbinom()'* function can be used is the following:

  - Let's say that there are 20 multiple choice questions in test, and that each of the 20 questions has 4 possible multiple choice answers and only one option is correct - meaning that there is 25% probability of getting each question right. We wish to find the probability of having an A on this test, which would require a result of 90% correct and above. This means we would need to answer 18 of the questions correct. If we were to not study, have no familiarity with any content on this test, and select answers at random, what would be the chance of getting 18 questions right?

```{r dbinom_example_3}
dbinom(18, size=20, prob=.25) # The result is 0% chance. 
```

  -Let's say we just wish to pass the test with a grade C at 60% correct answers. This would require 12 answers to be correct. 
```{r dbinom_example_4}
dbinom(12, size=20, prob=.25)# The result is 0% chance.
```
  
  - Lastly, let's say we wish to find what the individual success rates for each question would be if we were to be successful with 18 or less questions:
  
```{r dbinom_example_5}
dbinom(0:12, size = 20, prob=.25)

x_dbinom_2 <- seq(0, 18, by = 1) # Creates a sequence of equally spaced numbers between specified values.
y_dbinom_2 <- dbinom(x_dbinom_2, size = 20, prob = .25) # Apply the dbinom function.
plot(x_dbinom_2, y_dbinom_2, # Plot dbinom values.
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") 
```
  
  - We can see that the each x value representing each of the 20 questions has its correct answer probability indicated by the y value. Similar to the normal distribution functions, the total area underneath the curve sums up to 1 or 100%, which leads us to the next section, the cumulative binomial function. 
  
  
## 'pbinom()'

*pbinom(q, size, prob, lower.tail)*

Similarly to normal distribution functions, *'pbinom()'* function shows the distribution of the function. This function provides the probability of *less than or equal to* or *greater than or equal to* successful trials (*q*) from a number of total trials (*size*), and a probability of a positive outcome (*prob*). The *lower.tail* variable in the command is logical. When *TRUE* (default), it implies probability of less than or equal to x (or *q*), and when *FALSE*, it implies greater than or equal to x (or *q*). 

This binomial distribution helps us calculate the cumulative probabilities in a given range.

- Referring back to the practical example from the *'dbinom()'* function section, we will show how the sum of individual successes is the same as using the cumulative *'pbinom()'* function. 

```{r pbinom_example_1}
dbinom(0:12, size = 20, prob=.25) # Individual success rate (12 or less questions). 
sum (dbinom(0:12, size = 20, prob=.25)) # Cumulative probability (12 or less questions') success rates. Result = 99%.
sum (dbinom(0:4, size = 20, prob=.25)) # Cumulative probability for 4 or less questions' success rates. This result is 41%.
sum (dbinom(0:20, size = 20, prob=.25)) # Cumulative probability for all 20 questions' success rates always equals to 1, or 100%. 
```

- The *'pbinom()'* function example is shown below. We will ask the cumulative probability of obtaining 10 or less successful outcomes, with a trial size of 20 and probability of 20%. The follow up scripts will increase the probability and the number of trials for comparison.

```{r pbinom_example_2}

pbinom(10, 20, 0.2) # This function asks for a exactly 10 successful outcomes.
pbinom(10, size = 10, prob = .2) # This function can be written like this. 
pbinom(10, 10, .2) # This function can also be written like this as well.

pbinom(10, 10, .6) # Changing the probability for comparison

pbinom(10, 20, .2) # Changing the size, or number of trials, for comparison

pbinom(10, 20, .6) # Changing the size and probability for comparison

pbinom(0:10, 10, .2) #We can also ask for a range of 10 or less successful outcomes using a function like this. The next example below will graphically illustrate these ranges.
```

-The following example plots these concepts into line graphs, for comparisons:

```{r pbinom_example_3}
x_pbinom <- seq(0, 10, by = 1) # Creates a sequence of equally spaced numbers between specified values.

y_pbinom <- pbinom(x_pbinom, size = 10, prob = .2) # Apply the pbinom function.
plot(x_pbinom, y_pbinom, # Plot pbinom values.
     type="l", # Specifies a line type graph, default is open circle points.
     lwd=2, # Specifies line thickness.
     col ="blue", # Specifies line color.
     xlab = "X", # Specifies x-axis title.
     ylab = "Y") # Specifies y-axis title.

pbinom(0:10, 10, .2) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

y_pbinom <- pbinom(x_pbinom, size = 10, prob = .6) # Changing the probability for comparison.
plot(x_pbinom, y_pbinom, 
     type="l", 
     lwd=2, 
     col ="red", 
     xlab = "X", 
     ylab = "Y") 

pbinom(0:10, 10, .6) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

y_pbinom <- pbinom(x_pbinom, size = 20, prob = .2) # Changing the size for comparison.
plot(x_pbinom, y_pbinom, 
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") 

pbinom(0:10, 20, .2) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.

y_pbinom <- pbinom(x_pbinom, size = 20, prob = .4) # Changing the size and probability for comparison.
plot(x_pbinom, y_pbinom, 
     type="l", 
     lwd=2, 
     col ="red",
     xlab = "X", 
     ylab = "Y") 

pbinom(0:10, 10, .4) #The resulting answers correspond with the y-axis probability for each x value in the range from 0 to 10.
```

-A practical example of the *'pbinom()'* function is the following:
  - Let's say that there is a vaccine with success rate of 95%, and that we have a group of 20 people. We wish to know what is the probability that all 400 or fewer people will respond positively to this vaccine. 
  
```{r pbinom_example_4}
pbinom(400, 400, .95) #Result is 1 or 100%. This doesn't give us a full picture because if any number lower than 400 is considered a success, the result is obviously 100%. 
```
  
  - Thus, we need to find the individual probabilities of a range between 0 to 400 people from a group of 400 who will respond positively to this vaccine. We will graph two scenarios, one with success rate at 95%, and second at a lower success at 60%. 
  
```{r pbinom_example_5}
pbinom(0:400, 400, .95) #Result is 100%, implying that this vaccine is safe.

x_pbinom <- seq(1,400, by = 1)
y_pbinom <- pbinom(x_pbinom,400, .95)
plot(x_pbinom, y_pbinom, # Plot pbinom values.
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") # Results show that about 380 people will respond positively to the vaccine.

x_pbinom <- seq(1,400, by = 1)
y_pbinom <- pbinom(x_pbinom,400, .60)
plot(x_pbinom, y_pbinom, # Plot pbinom values.
     type="l", 
     lwd=2, 
     col ="blue", 
     xlab = "X", 
     ylab = "Y") # Results show that about 220 people will respond positively to the vaccine.
```


## 'qbinom()'

*qbinom(p, size, prob, lower.tail)*

Similar to normal distribution functions, the *'qbinom()'* function gives the quantile. Also, this quantile function is the opposite of *'pbinom()'*. It provides the number of successful trials less than or equal to a probability *p* of a positive outcomes, the *size* of the total number of trials, and the probability of a positive trial *prob*. The *lower.tail* variable in the command is logical. When *TRUE* (which is default), it implies probability of less than or equal to x (or *p*), and when *FALSE*, it implies greater than or equal to x (or *p*).

- The *'qbinom()'* function example is shown below. Referring to the previous example, as this function is the inverse of *'pbinom()'*, we will ask for the bottom 20% of outcomes with the 95% success rate and 400 patients, and also with the 60% success rate and 400 patients who responded positively to this vaccine.

```{r qbinom_example_1}
qbinom(.20, 400, .95) # Result was 376 persons. This was very close to our visual estimate of the plotted graph.
qbinom(.20, 400, .6) # Result was 232 persons. This was also very close to our visual estimate of the plotted graph.

#These results state that in 20% of the trials, the above number results of people will have a positive response to the vaccine given its clinical success rates of 95% and 60%. 
```

- If we wanted to calculate the bottom quantile of 99.9% of outcomes for the same success rates and numberof patients, we would run the following script:
```{r qbinom_example_2}
qbinom(.999, 400, .95) # Result was 392 persons. This was very also close to our visual estimate of the plotted graph.
qbinom(.999, 400, .6) # Result was 270 persons. This was also very close to our visual estimate of the plotted graph. 
```


# Functions 5: Other Functions {.tabset .tabset-pills}

## 'subset()'

The *'subset()'* function is used as an indexing feature for accessing object elements. It can be used to select and filter variables and observations. This is particularly useful for large data sets. This function selects specified rows and columns from a data frame, and creates a vector of these values that can be used in subsequent scripts for a narrower data set analysis. 

- An example of the *'subset()'* function is shown below, using the existing data of the *palmerpenguins* data set.
```{r subset_example_1}
summary(penguins) # Summary of the "palmerpenguins' data set. 

subset(penguins, species == "Chinstrap") #Subset of the Chinstrap species
chinstrap <- subset(penguins, species == "Chinstrap") #Subset of the Chinstrap species placed in vector

subset(chinstrap, sex == "female") # Subset of the Chinstrap species female sex
female_chinstrap <- subset(chinstrap, sex == "female") # Subset of the Chinstrap species female sex placed in a vector
```

## 'libary() and require()'

R packages are a collection of R functions, which include complied code and sample data, and are stored under a directory called *library* in the R environment. By default, R installs a set of packages during installation. 

Running the *'library()'* function empty lists all the available packages, installed by default. Running this function with a specified package will promt and error message if it is not available or load into project if it is available. Similarly, running the *'require()'* function for a particular package, loads that specified package into a project in R. The main difference is the phrasing of the error code in case the requested package is not installed, and that the library function by itself opens a new window in R with a full list of all available data sets to choose from.

-An example of these two functions using the *palmerpenguins* data set is shown below:

```{r library_and_require_example_1, error = TRUE}

library() # This script opens a new window in R studio listing all the available packages. This is useful for a preview of all available data set titles and brief descriptions. We can see that palmerpenguins is available. 

library(palmerpenguins)# This script, with the direct input of the data set we are interested in, will output an error message if this data set is not installed.

library(xyz) # In this example, as the data set "xyz" does not exist, an error message is displayed.

require(palmerpenguins) # This script loads this available data set into the project. 

require(xyz) # In this example, as the data set "xyz" does not exist, an error message is displayed.

```


## 'read.csv()'

The *'read.csv()'* function tells R where to locate the data file for analysis. There are two ways to get to a file in R, first using a relative path and second using an absolute path. 


- An example of how to use the *'read.csv()'* function is explained in the example below:

```{r here_example_1}

require("here") # Loading this script from R package library which will help set the origin directory

here("data", "hab.sta.csv") # This function helps locate the "data" folder directory when it cannot be found and is set someplace outside of the R project directory. The output will provide the absolute path to the file. 

file.exists(here("data", "hab.sta.csv")) # This scripts verifies the location of the data file and its directory. The output is TRUE in this case.

read.csv(here("data", "hab.sta.csv")) # This script embeds the here command into the read.csv command, it tells R where the data file and its directory are and to read the data file in a single step script. 

dat_habitat<- read.csv(here("data", "hab.sta.csv")) # This script creates a data frame of the imported data file
```


# Part 2: Data Anaylsis

## Numerical Exploration

```{r}
delomys= read.csv("https://michaelfrancenelson.github.io/eco_602_634_2020/data/delomys.csv")
summary(delomys$body_mass)
summary(delomys$body_length)
shapiro.test(delomys$body_mass)
shapiro.test(delomys$body_length)

```

## Graphical Exploration {.tabset .tabset-pills}

### Scatterplot 
Body Mass and Body Length
```{r}
plot(body_length~body_mass, data = delomys)

```

### Histogram
Body Length

```{r}
hist(delomys$body_length, main = "Delomy Body Length Histogram",
     xlab = "Body length ",
     ylab = "Frequency") 
```

Body Length

```{r}
hist(delomys$body_mass, main = "Delomy Body Mass Histogram",
     xlab = "Body Mass",
     ylab = "Frequency",
     )
```

### Conditional Boxplot 
Body mass, conditioned on species (column binomial)

```{r}
boxplot(body_mass~binomial, data=delomys,
        main = "Conditional Boxplot of Body Mass and Species",
        xlab = "Species",
        ylab = "Body Mass")
```

Body mass conditioned on sex

```{r}
boxplot(body_mass~sex, data=delomys,
        main = "Conditional Boxplot of Body Mass And Sex",
        xlab = "Sex",
        ylab = "Body Mass"
          )

```

Body mass, conditioned on both species and sex

```{r}
boxplot(body_mass~binomial * sex, data=delomys,
        main = "Conditional Boxplot Of Body Mass On Both Species And Sex",
        xlab = "Species And Sex",
        ylab = "Body Mass",
        names = c("D.dorsalis - F", "D.sublineatus - F", "D.dorsalis - M", "D.sublineatus - M")
          )
```

### Quesitons

  Question 1:
  
  - Qualitatively describe the relationship between body mass and length. Does the relationship seem linear, curved, nonexistent?
  
    The relationship between body mass and body length is clustered but has a generally linear relationship. The linear trend in the graph shows that when body length increases, body mass generally increases as well. The points that are farther away from the main cluster trend represent statistical anomalies, for example the delomys points at the top of the boxplot show above average body length for their weight. I would describe these rodents as long and skinny.
  
  Question 2:
  
  - Qualitatively describe the shapes of the histograms. Do the data appear normally-distributed? Explain why or why not.

    - Body Mass Histogram:  
      - The body mass histogram appears to be normally distributed which shows a bell pattern. There does seem to be a slight skew to the right. There is a clear minimum range, median range, and max range. As body mass increase, there are less frequency occurances. 
      
    - Body Length Histogram:
      - The body length histogram shows that most of the occurances are measured as between 100 and 140 (there are no units listed). The distribution of the body length data is not normally distributed. The data shows that this species grows to a consistant legnth range with little distribution. Therefore I would describe this distribution as not varying.
  
  Question 3:
  
  - Using both the histograms and normality tests, do you think the (unconditioned) body masses and body length are normally-distributed?

    The shapiro normality tests showed p-vlaues of 4.33e-05 (body mass) and 2.2e-16 (body length). Since both of these p-values are less than 0.05, the test indicates that the normality of the distribution is not normal.

  Question 4:
  
  - Contrast your visual assessment of normality to the results of the numerical normality tests.
Examine the conditional boxplots. Describe any graphical evidence you see for body mass differences based on species and/or sex.

    Visually, the body mass histogram appears to be normal, however the shapiro test shows the distribution as non normal. FOr the body length histogram, the data appears not to be normally distributed and this is confirmed by the shapiro test. 
    The conditional boxplot based on species creates an interesting comparison among the variable types. For instance, there isnt that much of a difference between species, as males are typically are bigger among species. The coonditonal boxlot also makes sense to create because the D.dorsalis female is slightly bigger than the D.sublineatus Male. This is an interesting comparison that is shown. 

## Model Building {.tabset .tabset-pills}

### Model 1
Simple Linear Regression Body Length ~ Body Mass

```{r}
fit1 = lm(body_length ~ body_mass, data= delomys)
coef(fit1)



```

### Model 2
1-way ANOVA Body Mass ~ Sex

```{r}
fit2 = lm(body_mass ~ sex, data=delomys)
summary(fit2)
anova(fit2)

```

### Model 3
1-Way ANOVA Body_Mass ~ Binomial

```{r}
fit3 = lm(body_mass~binomial, data = delomys)
summary(fit3)
anova(fit3)
```

### Model 4
2-Way Additive ANOVA Body Mass ~ Sex + Binomial

```{r}
fit4 = lm(body_mass~sex + binomial, data = delomys)
summary(fit4)
anova(fit4)
```

### Model 5
2-Way Factorial ANOVA Body Mass ~ Sex * Binomial

```{r}
fit5 = lm(body_mass~sex * binomial, data = delomys)
summary(fit5)
anova(fit5)
```


## Model Diagnostics {.tabset .tabset-pills}

### Residuals Histograms

```{r}
fit1residual <- residuals(fit1) #Body mass to body length
fit2residual <- residuals(fit2)
fit3residual <- residuals(fit3)
fit4residual <- residuals(fit4)
fit5residual <- residuals(fit5)

hist(fit1residual, breaks = 30, main = "Fit 1 Residuals Histogram")
hist(fit2residual, breaks = 30, main = "Fit 2 Residuals Histogram")
hist(fit3residual, breaks = 30, main = "Fit 3 Residuals Histogram")
hist(fit4residual, breaks = 30, main = "Fit 4 Residuals Histogram")
hist(fit5residual, breaks = 30, main = "Fit 5 Residuals Histogram")
```

### Shapiro Tests

```{r}
shapiro.test(fit1residual)
shapiro.test(fit2residual)
shapiro.test(fit3residual)
shapiro.test(fit4residual)
shapiro.test(fit5residual)
```

### Questions

  Question 1:
  
  - What do you conclude about residual normality based on the numerical and graphical diagnostics?
  
    From a graphical standpoint, all of the histograms appear to have a normal distribution with the exception of fit1residual. From a numerical standpoint, the shapiro test shows all p-values below 0.05. This rejects the hypothesis of normal distribution posed by the shapiro-Wilk test. 

  Question 2:
  
  - Are violations of the normality assumption equally severe for all the models?
  
    While all of the fitresidual shapiro tests show a non normal distribution, the p- vlaues differ in severity which indicates varying degree's of non normality. For instance, the shapiro test for fit1residual has a much smaller p-value which indicates that this distribution is less normally distributed compared to fitresiduals 2 through 5.  

## Model Interpretation {.tabset .tabset-pills}

Printing Coefficient table

```{r}
knitr::kable(coef(summary(fit1)))
knitr::kable(coef(summary(fit2)))
knitr::kable(coef(summary(fit3)))
knitr::kable(coef(summary(fit4)))
knitr::kable(coef(summary(fit5)))

```

### Body Length Questions:

```{r}
#Model Coefficient Table Body Length~Body Mass. Intercept = Body Length
knitr::kable(coef(summary(fit1))) 
#Scatter Plot Body Length~Body Mass
plot(body_length~body_mass, data = delomys)

```

  Question 1:
    
  - What is the magnitude of the mass/length relationship?
    
      Magnitude is represented by the slope.
      
  Question 2:
  
  - What is the expected body length of an an animal that weighs 100g?
    
      76.1246565 is the base and then you'd add 100 to this because we're looking to find the body length of an animal that weighs 100g. #Not sure if this is correct
    
  Question 3:
  
  - What is the expected body length of an animal that weighs 0g?
    
      It would be the intercept value of 76.1246565 grams.
      
### Body Mass Coefficients Questions

  Body Mass and Sex:

```{r}
knitr::kable(coef(summary(fit2)))
```

  Question 1: 
  
  - What is the base level for sex?
  
    The base is 42.711465
  
```{r}
knitr::kable(coef(summary(fit3)))
```

  Question 2: 
  
  - What is the base level for binomial?
  
    The base is 46.752427

  Question 3: 
  
  - Which sex is heavier?
  
    The Males

  Question 4: 
  
  - Which species is heavier?
  
    Delomy Dorsalis is the heavier species. 
    
### ANOVA: Coefficients Questions

  Question 1: 
  
  - Are sex and species significant predictors for body mass?
  
    Yes, since the p value is less than 0.05.

  Question 2:
  
  - Is there a significant interaction?
  
    There no significant interaction

  Question 3:
  
  - Does the significance (as measured by p-value) of either of the main effects (sex and species) differ much between the single-predictor models, the additive model, and the interactive model?
  
    No they don't.
      

## Model Comparison

```{r}
AIC(fit1)
AIC(fit2)
AIC(fit3)
AIC(fit4)
AIC(fit5)

```

  Question 1:
  
  - Which two models have the lowest AIC?
  
    AIC fit1 and AIC fit2 have the lowest AIC.
  
  Question 2:
  
  - Which of the two models with lowest AIC scores would you select?
Explain your decision based on model fit and the complexity/understanding tradeoff.

  Models 4 and 5 have the lowest AIC values and both have similar results, therefore both the 2-way additive ANOVA and 2-way factorial ANOVA would be used.














